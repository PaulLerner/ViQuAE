{
    "trainee": {
        "class_name": "DPRBiEncoder",
        "pretrained_model_name_or_path": "bert-base-uncased"
    },
    "trainer_class": "DPRBiEncoderTrainer",
    "tokenizer": {
        "class_name": "BertTokenizer",
        "pretrained_model_name_or_path": "bert-base-uncased"
    },
    "verbosity": 10,
    "train_dataset": "data/viquae_dataset/train",
    "eval_dataset": "data/viquae_dataset/validation",
    "metric": "retrieval",
    "kb": "data/viquae_passages",
    "M": 2,
    "n_relevant_passages": 1,
    "search_key": "BM25",
    "tokenization_kwargs": {
        "max_length": 256,
        "padding": "max_length"
    },
    "checkpoint": {
        "resume_from_checkpoint": "experiments/dpr/kilt/checkpoint-13984"
    },
    "callbacks_args": [
        {
            "Class": "EarlyStoppingCallback",
            "early_stopping_patience": 10
        }
    ],
    "training_kwargs": {
        "do_train": true,
        "do_eval": false,
        "do_predict": false,
        "group_by_length": false,
        "output_dir": "experiments/dpr/viquae",
        "logging_dir": "experiments/dpr/viquae",
        "evaluation_strategy": "epoch",
        "prediction_loss_only": false,
        "per_device_train_batch_size": 32,
        "per_device_eval_batch_size": 128,
        "gradient_accumulation_steps": 1,
        "eval_accumulation_steps": 1,
        "max_grad_norm": 2.0,
        "num_train_epochs": 40,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "lr_scheduler_type": "linear",
        "warmup_steps": 1237,
        "logging_strategy": "epoch",
        "save_strategy": "epoch",
        "dataloader_num_workers": 0,
        "dataloader_pin_memory": true,
        "adam_beta1": 0.9,
        "adam_beta2": 0.999,
        "adam_epsilon": 1e-8,
        "local_rank": null,
        "ignore_data_skip": false,
        "remove_unused_columns": false,
        "greater_is_better": true,
        "load_best_model_at_end": true,
        "metric_for_best_model": "eval_MRR@N*M",
        "report_to": "tensorboard",
        "label_names": ["labels"]
    }
}
